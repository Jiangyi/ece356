\include{header}

\begin{document}

\lecture{ 24 --- Timestamp Protocols }{\term}{Jeff Zarnett}

\section*{Concurrency via Timestamps}

Beyond just doing concurrency through some sort of locking protocol, we can also use timestamps for arranging concurrency. The timestamp, as you will recall, is a unique identifier, and they are typically assigned in the order the transactions are submitted to the system~\cite{fds}. If timestamps are used appropriately, then consistent results are produced without the use of any locks or locking, meaning deadlock can never occur.

The notation for the timestamp of a transaction $T$ is $T\!S(T)$. The transactions can be ordered based on their timestamps; if a transaction $T_{i}$ arrives and then later another transaction $T_{j}$ arrives, then $T\!S(T_{i}) < T\!S(T_{j})$. If two transactions arrive at exactly the same time, then some sort of serialization procedure will be needed to make sure that they are not identical. It is commonly the case that the system clock is used to get the time stamp; just read the current value of the clock and use that.

The alternative is a logical counter: increment a simple integer counter for each transaction. After a timestamp is assigned, just increment the counter. Eventually there is a limit (even if you can have $2^{64}$ transactions, in theory, which is quite a lot, but not infinite) but at some point the transaction counter will need to roll over or reset.

Generation of the timestamps is fairly simple, it would seem, but what are they for? Timestamps are used for serializability order in the schedule; the system must ensure that the schedule executed is equivalent to a serial schedule in which transactions are ordered according to their timestamps (ascending)~\cite{dsc}. Note that this is very different from two-phase locking. In two phase locking, a schedule is serializable by being equivalent to some schedule that is permitted under the locking rules; in timestamp ordering the schedule is equivalent to the a particular serial ordering matching ascending transaction timestamps~\cite{fds}.

Every data element in the database is associated with separate timestamps for reading and writing. The notation can vary: in~\cite{fds} they are called \textbf{read\_TS} and \textbf{write\_TS}; in~\cite{dsc} they are \textbf{r-timestamp} and \textbf{w-timestamp}. To save space I might personally like $T\!S_{r}$ and $T\!S_{w}$. Each time the a data element $X$ is read or written, its appropriate timestamp is updated to the timestamp of the transaction performing the read or write.

The formal definition of the read timestamp of an item $X$: the largest timestamp amongst all the timestamps of transactions that have successfully read $X$. So $T\!S(X) = T\!S(T_{k})$ where $T_{k}$ is the youngest transaction that has read $X$ successfully~\cite{fds}.

The formal definition of the write timestamp of an item $X$: the largest timestamp amongst all the timestamps of transactions that have successfully written $X$. So $T\!S(X) = T\!S(T_{k})$ where $T_{k}$ is the youngest transaction that has written $X$ successfully~\cite{fds}.

Unfortunately, simple timestamp ordering does not avoid the risk of cascading rollback. Schedules are not guaranteed to be recoverable. This leads us to the \textit{timestamp ordering protocol} as described in~\cite{dsc}.

For a read operation $T_{i}$ is performing on $X$:
\begin{enumerate}
	\item If $T\!S(T_{i}) < T\!S_{w}(X)$ then $T_{i}$ needs to read a value of $X$ that was already overwritten -- and therefore the read operation is not permitted and $T_{i}$ is rolled back.
	\item If $T\!S(T_{i}) \geq T\!S_{w}(X)$ the read operation is executed and $T\!S_{r}$ is set to $\max ( T\!S(T_{i}),~T\!S_{r}(X))$.
\end{enumerate}

For a write operation $T_{i}$ is performing on $X$:
\begin{enumerate}

\item If $T\!S(T_{i}) < T\!S_{r}(X)$ then the value that $T_{i}$ is producing was needed previously but the system assumed it wasn't going to happen and proceeded without it; thus the write is not permitted and $T_{i}$ is rolled back.
\item If $T\!S(T_{i}) < T\!S_{w}(X)$ then $T_{i}$ is attempting to write an obsolete value; the write is not permitted and $T_{i}$ is rolled back.
\item Otherwise, the write proceeds and $T\!S_{w}(X)$ is updated to $T\!S(T_{i})$. 

\end{enumerate}

When a transaction is rolled back and restarted, the transaction is assigned a new timestamp. The timestamp ordering protocol does provide us with conflict serializability, because conflicting operations are processed in timestamp order. Because there are no locks, there cannot be deadlocks -- but can starvation still occur? The answer is yes, a very long transaction might be constantly frustrated by shorter transactions constantly swooping in and making changes that force a rollback of the long transaction. Unfortunately it might be necessary to block other transactions and let the long one finish~\cite{dsc}.

It is worth noting that neither two phase locking nor the simple timestamp ordering protocol covers all serializable schedules; that is, there are some that are valid under one but not valid under the other~\cite{fds}. That's fine, as far as we are concerned -- we don't need to consider all possibilities; we will get enough choices.

If we would like to recoverability we can have strict timestamp ordering. In strict timestamp ordering, a transaction $T_{i}$ that issues a read or write of an item $X$ where $T\!S(T_{i}) > T\!S_{w}(X)$, then the read or write operation is delated until the transaction that last wrote $X$ has either committed or aborted. This, in some way, requires simulating locking item $X$ until a previous write has been committed or aborted, but there cannot be a deadlock because a transaction can only wait on an older transaction (one with a  lower timestamp)~\cite{fds}.

\paragraph{Thomas's Write Rule.} A modification of the basic algorithm called Thomas's Write Rule (or the Thomas\footnote{Named after the author of the paper describing this rule, Robert H. Thomas} Write Rule) allows greater concurrency than the basic algorithm and also, hopefully, rejects fewer writes. To explain it simply, it is ``ignore outdated writes''.

More formally, the write item checks are modified to the following~\cite{fds}:
\begin{enumerate}
	\item If $T\!S_{r}(X) > T\!S(T_{i})$ then abort and roll back $T_{i}$ (write rejected).
	\item If $T\!S_{w}(X) > T\!S(T_{i})$, then do not execute the write, but continue executing (do not roll back the transaction).
	\item Otherwise, the write proceeds and $T\!S_{w}(X)$ is updated to $T\!S(T_{i})$. 
\end{enumerate}

This requires some explanation. If a transaction $T_{i}$ is going to write an old value, under the previous scheme that write would be rejected. Under Thomas's Write Rule, we will just skip doing the write (the value to be written is outdated) and we just carry on. Essentially we just pretend that the write happened but was immediately overwritten by the more up to date value. 


\input{bibliography.tex}

\end{document}
